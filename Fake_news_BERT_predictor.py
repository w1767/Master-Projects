# -*- coding: utf-8 -*-
"""Nathan_project)_fnal.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1alAMywP4kvXLEUhFiXJEHEE4zT0Rxpi4
"""

import pandas as pd

df = pd.read_csv(r"/content/WELFake_Dataset.csv", engine='python', on_bad_lines='skip')

df.head(5)

df["label"].value_counts()

df = df.drop(columns=["Unnamed: 0"])

df.head(5)

df = df.dropna(subset=["text"])

df["title"] = df["title"].fillna("").astype(str) if "title" in df.columns else ""
df["text"]  = df["text"].fillna("").astype(str)
df["full_text"] = (df["title"].str.strip() + " " + df["text"].str.strip()).str.strip()
df = df[df["full_text"].str.len() > 0].reset_index(drop=True)

len(df)

X = df["full_text"]
y = df["label"]

X.head(5)

import re
import string
import nltk
nltk.download("stopwords")

from nltk.corpus import stopwords
stop_words = set(stopwords.words("english"))

def clean_text(text):
    text = text.lower()
    text = re.sub(r'https?://\S+|www\.\S+', '', text)
    text = re.sub(r'<.*?>+', '', text)
    text = re.sub(r'[%s]' % re.escape(string.punctuation), '', text)
    text = re.sub(r'\n', '', text)
    text = re.sub(r'\w*\d\w*', '', text)
    return " ".join(word for word in text.split() if word not in stop_words)

X = X.apply(clean_text)

X.head(5)

from sklearn.model_selection import train_test_split

# Filter X and y to only include valid labels (0 or 1)
# This addresses the TypeError by removing non-numeric/inconsistent labels
valid_label_mask = y.astype(str).isin(['0', '1'])
X_filtered = X[valid_label_mask]
y_filtered = y[valid_label_mask].astype(int) # Ensure y is integer type for stratification

X_train, X_temp, y_train, y_temp = train_test_split(
    X_filtered,
    y_filtered,
    test_size=0.3,
    random_state=42,
    stratify=y_filtered # Stratify using the cleaned y
)

X_val, X_test, y_val, y_test = train_test_split(
    X_temp,
    y_temp,
    test_size=0.5,
    random_state=42,
    stratify=y_temp
)

len(X_train),len(X_val),len(X_test)

len(X)

from sklearn.feature_extraction.text import TfidfVectorizer

vectorizer = TfidfVectorizer(
    max_features=5000,
    ngram_range=(1, 2)
)
X_train_vec = vectorizer.fit_transform(X_train)
X_val_vec = vectorizer.transform(X_val)
X_test_vec = vectorizer.transform(X_test)

from sklearn.linear_model import LogisticRegression

model = LogisticRegression(max_iter=1000)
model.fit(X_train_vec, y_train)

print("Unique labels:", sorted(df["label"].astype(str).loc[df["label"].astype(str).isin(['0', '1'])].unique().astype(int)))

from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

y_pred = model.predict(X_test_vec)

print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))

6574/(6574+432),(7099/(7099+314))

6574/(6574+314),7099/(7099+432)

def predict_news(news):
    news = clean_text(news)
    vec = vectorizer.transform([news])
    return "FAKE" if model.predict(vec)[0] == 1 else "REAL"
print(predict_news("Breaking: Scientists discover new planet similar to Earth"))

import shap
explainer = shap.LinearExplainer(
    model,
    X_train_vec,
    feature_names=vectorizer.get_feature_names_out()
)

sample_index = 0
X_sample = X_test_vec[sample_index]

shap_values = explainer.shap_values(X_sample)

shap.plots.waterfall(shap.Explanation(
    values=shap_values[0],
    base_values=explainer.expected_value,
    feature_names=vectorizer.get_feature_names_out()
))

shap.summary_plot(
    explainer.shap_values(X_train_vec),
    feature_names=vectorizer.get_feature_names_out()
)

!pip -q install lime
from lime.lime_text import LimeTextExplainer
from sklearn.pipeline import make_pipeline
class_names = ["Real", "Fake"]
lime_pipeline = make_pipeline(vectorizer, model)
explainer = LimeTextExplainer(class_names=class_names)
sample_text = X_test.iloc[0] if hasattr(X_test, "iloc") else X.iloc[0]
exp = explainer.explain_instance(sample_text, lime_pipeline.predict_proba, num_features=12)
exp.show_in_notebook(text=True)

feature_names = vectorizer.get_feature_names_out()
coefficients = model.coef_[0]

coef_df = pd.DataFrame({
    "word": feature_names,
    "importance": coefficients
})
print(coef_df.sort_values(by="importance", ascending=False).head(10))
print(coef_df.sort_values(by="importance").head(10))

from sklearn.svm import LinearSVC
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

svm_model = LinearSVC()
svm_model.fit(X_train_vec, y_train)

y_pred_svm = svm_model.predict(X_test_vec)

print("Accuracy:", accuracy_score(y_test, y_pred_svm))
print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred_svm))
print("\nClassification Report:\n", classification_report(y_test, y_pred_svm))

import shap

explainer = shap.LinearExplainer(
    svm_model,
    X_train_vec,
    feature_names=vectorizer.get_feature_names_out()
)

sample_index = 0
X_sample = X_test_vec[sample_index]

shap_values = explainer.shap_values(X_sample)

shap_values_single = shap_values[0]

import shap

shap.plots.waterfall(
    shap.Explanation(
        values=shap_values_single,
        base_values=explainer.expected_value,
        feature_names=vectorizer.get_feature_names_out()
    )
)

import pandas as pd
import torch

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report

from transformers import (
    BertTokenizerFast,
    BertForSequenceClassification,
    Trainer,
    TrainingArguments
)

from datasets import Dataset

df = pd.read_csv(r"/content/WELFake_Dataset.csv", engine='python', on_bad_lines='skip')
df = df.dropna(subset=["text"])
df["title"] = df["title"].fillna("").astype(str) if "title" in df.columns else ""
df["text"]  = df["text"].fillna("").astype(str)
df["full_text"] = (df["title"].str.strip() + " " + df["text"].str.strip()).str.strip()
df = df[["full_text", "label"]]

df["label"].value_counts()

from sklearn.model_selection import train_test_split
import pandas as pd

# Filter df to include only rows where 'label' is 0 or 1
# Convert 'label' to string to use .isin() then to int for stratification
df_filtered = df[df['label'].astype(str).isin(['0', '1'])].copy()
df_filtered['label'] = df_filtered['label'].astype(int)

X_train, X_temp, y_train, y_temp = train_test_split(
    df_filtered["full_text"],
    df_filtered["label"],
    test_size=0.3,
    random_state=42,
    stratify=df_filtered["label"]
)

X_val, X_test, y_val, y_test = train_test_split(
    X_temp,
    y_temp,
    test_size=0.5,
    random_state=42,
    stratify=y_temp
)

train_df = pd.DataFrame({"full_text": X_train, "label": y_train})
val_df   = pd.DataFrame({"full_text": X_val,   "label": y_val})
test_df  = pd.DataFrame({"full_text": X_test,  "label": y_test})

from datasets import Dataset, DatasetDict
train_dataset = Dataset.from_pandas(train_df)
val_dataset   = Dataset.from_pandas(val_df)
test_dataset  = Dataset.from_pandas(test_df)

dataset = DatasetDict({
    "train": train_dataset,
    "validation": val_dataset,
    "test": test_dataset
})

tokenizer = BertTokenizerFast.from_pretrained("bert-base-uncased")

def tokenize(batch):
    return tokenizer(
        batch["full_text"],
        padding="max_length",
        truncation=True,
        max_length=256
    )

train_dataset = train_dataset.map(tokenize, batched=True)
val_dataset   = val_dataset.map(tokenize, batched=True)
test_dataset  = test_dataset.map(tokenize, batched=True)
train_dataset.set_format(
    type="torch",
    columns=["input_ids", "attention_mask", "label"]
)
val_dataset.set_format(
    type="torch",
    columns=["input_ids", "attention_mask", "label"]
)
test_dataset.set_format(
    type="torch",
    columns=["input_ids", "attention_mask", "label"]
)

model = BertForSequenceClassification.from_pretrained(
    "bert-base-uncased",
    num_labels=2
)

from sklearn.metrics import accuracy_score, precision_recall_fscore_support

def compute_metrics(pred):
    labels = pred.label_ids
    preds = pred.predictions.argmax(-1)

    acc = accuracy_score(labels, preds)
    precision, recall, f1, _ = precision_recall_fscore_support(
        labels, preds, average="binary", zero_division=0
    )
    return {
        "accuracy": acc,
        "precision": precision,
        "recall": recall,
        "f1": f1
    }

from transformers import TrainingArguments

training_args = TrainingArguments(
    output_dir="./bert_wellfake",
    do_train=True,
    do_eval=True,
    eval_steps=500,
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    learning_rate=2e-5,
    num_train_epochs=3,
    weight_decay=0.01,
    logging_dir="./logs",
    logging_steps=500,
    save_steps=500,
    report_to="none"
)

import os
os.environ["WANDB_DISABLED"] = "true"
import os
os.environ["WANDB_DISABLED"] = "true"

from transformers import Trainer

from google.colab import drive
drive.mount('/content/drive')

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=val_dataset
)

trainer.train()

save_path = "/content/drive/MyDrive/bert_wellfake"

trainer.save_model(save_path)
tokenizer.save_pretrained(save_path)

print("✅ Model saved to Google Drive at:", save_path)

predictions = trainer.predict(test_dataset)
y_pred = predictions.predictions.argmax(axis=1)

print(classification_report(y_test, y_pred))

from google.colab import drive
drive.mount('/content/drive')

def predict_news_bert(text):
    device = next(model.parameters()).device

    inputs = tokenizer(
        text,
        return_tensors="pt",
        truncation=True,
        padding=True,
        max_length=256
    )


    inputs = {k: v.to(device) for k, v in inputs.items()}

    with torch.no_grad():
        outputs = model(**inputs)

    prediction = torch.argmax(outputs.logits, dim=1).item()
    return "FAKE" if prediction == 1 else "REAL"

text = "Trump’s piracy in the Caribbean won’t end with Venezuela"
print(predict_news_bert(text))

print(predict_news_bert(""))

import torch

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(device)

model.to(device)
model.eval()

def predict_news_bert(text):
    inputs = tokenizer(
        text,
        return_tensors="pt",
        truncation=True,
        padding=True,
        max_length=256
    )


    inputs = {k: v.to(device) for k, v in inputs.items()}

    with torch.no_grad():
        outputs = model(**inputs)

    pred = torch.argmax(outputs.logits, dim=1).item()
    return "FAKE" if pred == 1 else "REAL"

print(predict_news_bert(
    "Breaking: Reuters reports talks between US and China"
))

import numpy as np
import torch

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)
model.eval()

def bert_predict(texts):

    if isinstance(texts, np.ndarray):
        texts = texts.tolist()

    if isinstance(texts, str):
        texts = [texts]


    texts = [str(t) for t in texts]

    inputs = tokenizer(
        texts,
        padding=True,
        truncation=True,
        max_length=256,
        return_tensors="pt"
    )

    inputs = {k: v.to(device) for k, v in inputs.items()}

    with torch.no_grad():
        outputs = model(**inputs)

    probs = torch.softmax(outputs.logits, dim=1)
    return probs.cpu().numpy()

import shap

explainer = shap.Explainer(
    bert_predict,
    masker=shap.maskers.Text(tokenizer)
)

text = "Trump’s piracy in the Caribbean won’t end with Venezuela"

shap_values = explainer([text])
shap.plots.text(shap_values)

import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns


bert_accuracy = 0.9850


models = ['Logistic Regression', 'SVM (Linear)', 'BERT ']
accuracies = [0.9480, 0.9536, bert_accuracy]

df_results = pd.DataFrame({
    'Model': models,
    'Test Accuracy': accuracies
})

df_results['Accuracy (%)'] = (df_results['Test Accuracy'] * 100).round(2).astype(str) + '%'

print("--- Figure 6.3: Model Performance Comparison ---")
display(df_results[['Model', 'Accuracy (%)']])

plt.figure(figsize=(8, 5))
ax = sns.barplot(x='Model', y='Test Accuracy', data=df_results, palette='viridis')

for i, v in enumerate(accuracies):
    ax.text(i, v + 0.002, f'{v:.2%}', ha='center', va='bottom', fontweight='bold')
plt.ylim(0.90, 1.0)
plt.title('Comparison of Model Accuracy', fontsize=14)
plt.ylabel('Accuracy', fontsize=12)
plt.xlabel('Model', fontsize=12)
plt.grid(axis='y', linestyle='--', alpha=0.5)

plt.tight_layout()
plt.show()

!pip -q install lime

import numpy as np
import torch
import torch.nn.functional as F
from lime.lime_text import LimeTextExplainer

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)
model.eval()

def bert_predict_proba(texts, max_length=256, batch_size=16):
    """
    Returns probabilities for each class for a list of texts.
    Shape: (len(texts), num_labels)
    """
    all_probs = []

    for i in range(0, len(texts), batch_size):
        batch_texts = texts[i:i+batch_size]

        enc = tokenizer(
            batch_texts,
            truncation=True,
            padding=True,
            max_length=max_length,
            return_tensors="pt"
        )

        enc = {k: v.to(device) for k, v in enc.items()}

        with torch.no_grad():
            outputs = model(**enc)
            probs = F.softmax(outputs.logits, dim=-1).detach().cpu().numpy()

        all_probs.append(probs)

    return np.vstack(all_probs)

import numpy as np
import torch
import torch.nn.functional as F

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)
model.eval()

def bert_predict_proba(texts, max_length=256, batch_size=16):
    """
    LIME-compatible probability function for BERT.
    Ensures model + inputs are always on the same device.
    """
    probs_all = []

    for i in range(0, len(texts), batch_size):
        batch_texts = texts[i:i+batch_size]

        enc = tokenizer(
            batch_texts,
            truncation=True,
            padding=True,
            max_length=max_length,
            return_tensors="pt"
        )


        enc = {k: v.to(device) for k, v in enc.items()}

        with torch.no_grad():
            outputs = model(**enc)
            probs = F.softmax(outputs.logits, dim=-1).detach().cpu().numpy()

        probs_all.append(probs)

    return np.vstack(probs_all)

from lime.lime_text import LimeTextExplainer

class_names = ["Real", "Fake"]
explainer = LimeTextExplainer(class_names=class_names)

text = "Trump’s piracy in the Caribbean won’t end with Venezuela."

exp = explainer.explain_instance(
    text_instance=text,
    classifier_fn=bert_predict_proba,
    num_features=12,
    num_samples=2000
)

exp.show_in_notebook(text=True)